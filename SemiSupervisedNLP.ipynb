{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.datasets import imdb\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Allocation of memory for the GPU process\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0],\n",
    "      [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=3072)])\n",
    "logical = tf.config.experimental.list_logical_devices('GPU')\n",
    "print(logical[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding\n",
    "max_features = 20000\n",
    "maxlen = 100\n",
    "embedding_size = 128\n",
    "\n",
    "# Convolution\n",
    "kernel_size = 5\n",
    "filters = 64\n",
    "pool_size = 4\n",
    "\n",
    "# LSTM\n",
    "lstm_output_size = 70\n",
    "\n",
    "# Training\n",
    "batch_size = 30\n",
    "epochs = 100 #modify as required, should be even\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "#Data split for unsupervised training\n",
    "x_train1 = x_train[0:5000]\n",
    "x_train2 = x_train[5001:24999]\n",
    "y_train1 = y_train[0:5000]\n",
    "y_train2 = y_train[5001:24999]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Build models...')\n",
    "\n",
    "class Network(Sequential):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.add(Embedding(max_features, embedding_size, input_length=maxlen))\n",
    "    self.add(Dropout(0.25))\n",
    "    self.add(Conv1D(filters, kernel_size, padding='valid', activation='relu', strides=1))\n",
    "    self.add(MaxPooling1D(pool_size=pool_size))\n",
    "    self.add(LSTM(lstm_output_size))\n",
    "    self.add(Dense(1))\n",
    "    self.add(Activation('sigmoid'))\n",
    "\n",
    "#Default for starting weights\n",
    "model = Network()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model_benchmark = Network()\n",
    "model_small_set = Network()\n",
    "model_iterative_training = Network()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Benchmark\n",
    "model_benchmark.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model_benchmark.set_weights(model.get_weights())\n",
    "\n",
    "print('Train Benchmark')\n",
    "model_benchmark.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),verbose=2)\n",
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Benchmark test score:', score)\n",
    "print('Benchmark test accuracy:', acc)\n",
    "model_benchmark.save('Mdl_Bench.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smaller training set\n",
    "print('Train on smaller set')\n",
    "model_small_set.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model_small_set.set_weights(model.get_weights())\n",
    "model_small_set.fit(x_train1, y_train1,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),verbose=2)\n",
    "score, acc = model_small_set.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Small model test score:', score)\n",
    "print('Small model test accuracy:', acc)\n",
    "model_small_set.save('Mdl_Small.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterative_train\n",
    "print('Train iter model')\n",
    "model_iterative_training.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model_iterative_training.set_weights(model.get_weights())\n",
    "\n",
    "model_iterative_training.fit(x_train1, y_train1,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs/2,\n",
    "          validation_data=(x_test, y_test),verbose=2)\n",
    "\n",
    "a = model_iterative_training.predict(x_train2)\n",
    "\n",
    "i = 0\n",
    "k = np.array([1])\n",
    "for x in np.nditer(a):\n",
    "     if x>=0.5:\n",
    "        x_train1 = np.append(x_train1, np.array([x_train2[i]]), axis = 0)\n",
    "        y_train1 = np.append(y_train1, k)\n",
    "        i += 1\n",
    "     else:\n",
    "        i += 1\n",
    "\n",
    "\n",
    "model_iterative_training.fit(x_train1, y_train1,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs/2,\n",
    "          validation_data=(x_test, y_test),verbose=2)\n",
    "\n",
    "score, acc = model_iterative_training.evaluate(x_test, y_test, batch_size=batch_size, verbose =2)\n",
    "print('Iterative test score:', score)\n",
    "print('Iterative test accuracy:', acc)\n",
    "model_iterative_training.save('Mdl_iter.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
